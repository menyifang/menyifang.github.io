---
layout: plainpage
title: Projects
excerpt: “Yifang Men’s Projects."
---


<h2>Research Projects</h2>

<h4>DCT-Net: Domain-Calibrated Translation for Portrait Stylization</h4>
<p style="font-size: 15px">
SIGGRAPH 2022 (TOG)<br>
Y. Men, Y. Yao, M. Cui, Z. Lian and X. Xie
</p>

<figure class="research-proj-img1">
    <img src="/images/projects/DCTNet_teaser.jpg" alt="" style="height: 200px; width:auto" border="0"/>
</figure>
<p style="font-size: 15px">
This paper introduces DCT-Net, a novel image translation architecture for few-shot portrait stylization, enabling advanced ability to high-preserving contents, strong generality to complicated real-world scenes, and high scalability to full-body translation with only head observations.

<br> <a href="https://menyifang.github.io/projects/DCTNet/DCTNet.html"><span class="label">Project Page</span></a>
         <a href="http://arxiv.org/abs/2207.02426"><span class="label">Paper</span></a>
         <a href="https://github.com/menyifang/DCT-Net"><span class="label">Code</span></a>
          <a href="https://www.youtube.com/watch?v=Y8BrfOjXYQM"><span class="label">Demo Video</span></a>
</p>
<br><br>

<h4>Unpaired Cartoon Image Synthesis via Gated Cycle Mapping</h4>
<p style="font-size: 15px">
CVPR 2022<br>
Y. Men, Y. Yao, M. Cui, Z. Lian, X. Xie and X. Hua
</p>

<figure class="research-proj-img1">
    <img src="/images/projects/UCIS_teaser.gif" alt="" style="height: 180px; width:auto" border="0"/>
</figure>
<p style="font-size: 15px">
A common cartoon translator which can not only simultaneously render exaggerated anime faces and realistic cartoon scenes, but also provide flexible user controls for desired cartoon styles.

<br> <a href="https://menyifang.github.io/projects/UCIS/UCIS.html"><span class="label">Project Page</span></a>
         <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Men_Unpaired_Cartoon_Image_Synthesis_via_Gated_Cycle_Mapping_CVPR_2022_paper.pdf"><span class="label">PDF</span></a>
          <a href="https://www.youtube.com/watch?v=USScq2tHQrQ"><span class="label">Demo Video</span></a>
</p>
<br><br>

<h4>Controllable Person Image Synthesis with Attribute-Decomposed GAN</h4>
<p style="font-size: 15px">
CVPR 2020<br>
Y. Men, Y. Mao, Y. Jiang, W. Ma and Z. Lian
</p>

<figure class="research-proj-img1">
    <img src="/images/projects/ADGAN_easer.gif" alt="" style="height: 180px; width:auto" border="0"/>
</figure>
<p style="font-size: 15px">This paper introduces Attribute-Decomposed GAN, a novel generative model for controllable person image synthesis, which can produce realistic person images with desired
human attributes (e.g., pose, head, upper clothes and pants) provided in various source inputs.

<br> <a href="https://menyifang.github.io/projects/ADGAN/ADGAN.html"><span class="label">Project Page</span></a>
         <a href="https://menyifang.github.io/projects/ADGAN/ADGAN_files/Paper_ADGAN_CVPR2020.pdf"><span class="label">PDF</span></a>
         <a href="https://github.com/menyifang/ADGAN"><span class="label">Code</span></a>
          <a href="https://youtu.be/hstN3lOWVHg"><span class="label">Demo Video</span></a>
</p>
<br><br>


<h4>DynTypo: Example-based Dynamic Text Effects Transfer</h4>
<p style="font-size: 15px">
CVPR 2019<br>
Y. Men, Z. Lian, Y. Tang, and J. Xiao
</p>

<figure class="research-proj-img1">
    <img src="/images/projects/DynTypo_easer.jpg" alt="" style="height: 180px; width:auto" border="0"/>
</figure>
<p style="font-size: 15px">In this paper, we present a novel approach for dynamic text effects transfer by using example-based texture synthesis and high-quality results
with temporal smoothing and sophisticated dynamic effects are acqired. 
<br>  <a href="https://menyifang.github.io/projects/DynTypo/DynTypo.html"><span class="label">Project Page</span></a>
          <a href="https://menyifang.github.io/projects/DynTypo/DynTypo_files/Paper_DynTypo_CVPR19.pdf"><span class="label">PDF</span></a>
          <a href="https://youtu.be/FkFQ6bV1s-o"><span class="label">Demo Video</span></a>
</p>
<br><br>



<h4>A Common Framework for Interactive Texture Transfer</h4>
<p style="font-size: 15px">
CVPR 2018<br>
Y. Men, Z. Lian, Y. Tang, and J. Xiao
</p>

<figure class="research-proj-img1">
    <img src="/images/projects/cfitt_easer.jpg" alt="" style="height: 300px; width:auto"/>
</figure>
<p style="font-size: 15px">In this paper, we present a general-purpose solution to interactive texture transfer problems including turning doodles into artworks, editing decorative patterns, generating texts in special effect as well as controlling effect distribution in text images, and swapping textures.

 <br><a href="https://menyifang.github.io/projects/CFITT/CFITT_files/Men_A_Common_Framework_CVPR_2018_paper.pdf"><span class="label">PDF</span></a>
     <a href="https://menyifang.github.io/projects/CFITT/CFITT.html"><span class="label">Project Page</span></a>
    <a href="https://menyifang.github.io/projects/CFITT/CFITT_files/poster_CFITT.pdf"><span class="label">Poster</span></a>


</p>
<br><br>


<h4>High Precision Gesture Sensing via Quantitative Characterization of the Doppler Effect</h4>
<p style="font-size: 15px">
ICPR 2016<br>
H. Ai, Y. Men*, L. Han, Z. Li, and M. Liu
</p>

<figure class="research-proj-img1">
    <img src="/images/projects/Gesture_easer.jpg" alt="" style="height: 360px; width:auto"/>
</figure>
<p style="font-size: 15px">This paper presents a high precision gesture recognition system that leverages the Doppler effect of ultrasound to sense in-air hand gestures. The system can precisely identify a wider variety of gestures than other systems without any modification to consumer laptops.

 <br><a href="https://menyifang.github.io/projects/GestureSense/Gesture_files/Gesture_Sense_ICPR_2016.pdf"><span class="label">PDF</span></a>
     <a href="https://menyifang.github.io/projects/GestureSense/Gesture.html"><span class="label">Project Page</span></a>

</p>
<br><br>


<h2>Course Projects</h2>

<h4>Ultrasonic Doppler-based Human-computer Interaction System</h4>

<figure class="course-proj-img">
    <img src="/images/projects/Doppler.png" alt="" />
    <figcaption>
    <p> 2016 - 2017 Fall</p>
    Implemented an HCI system using gesture sensing for 3D-characters control, album flip, etc. <br> 
 — the core algorithm for doppler-based gesture recognition <br>
 — 3D character controlling using Unity3D <br>
 — UI design and code programming with C# <br>

<a href="https://menyifang.github.io/projects/Doppler/Doppler.html"><span class="label">DETAIL</span></a>

    </figcaption>
</figure>

<div align="center">
<a href="https://menyifang.github.io">=&gt; Back to my personal website&lt;=</a>
</div>

